TO DO LIST FOR BAYESIM
----------------------

[* for necessary for paper, ~ for need to decide if it's necessary, - for future ideas]

* doc stuff:
  * add caveat that it's all subject to the model being "true"
  * add "prerequisites" or something section to docs
  * eventually, links in notebook examples to relevant bits of documentation...

* check "invalid value encountered in reduce" error

* parallelize model runs in function mode

* check passthrough subdivide options (excluding neighbors)

* more 'verbose' options

* add more options to CL interface (e.g. invoking comparison plot/visualize_grid, other tweaks to behavior)

* fix log spacing on visualize() in CL version

* fix save_step behavior in light of new run() protocol

* check 2.7 vs. 3.6 compatibility


~ entropy-based thresholding instead of th_pm and th_pv, also option to just specify min number of observation points per posterior that goes into the average

~ why is tol_digits ever getting set on logarithmic parameters (e.g. Bp in diode)

~ add calc_errors that takes a point in PMF (by index? as a dict?) and calculates average absolute and relative errors between model and observations for those parameters

~ parallelize model data rounding

~ uncertainty ending up as NaN in corners and maybe other places too?

~ change model.attach_params to call attach_ecs and attach_fit_params

~ either move true_vals star to x-axis or use a vertical line (and add legend for them)

~ include all options in argparser for command line

~ visualizing data with experimental and model uncertainty

~ visualizing model uncertainty on parameter grid

~ speed up visualize_grid somehow (parallelize?)

~ save model function somehow to at least theoretically close loop within CL interface

~ discard modeled EC points from file that aren't in observations rather than just importing and ignoring (in check_ecs function)

~ plotting points from an inference run?

~ figure out if list_model_pts_to_run can be made faster

~ for big data sets, save_state might need to write separate HDF5 files and store paths to them in the state file

~ make default value of th_pv (and th_pm?) dimension-number-dependent

~ option to give Python object (DataFrame) to attach_observations rather than only a file

~ play with code profiling to speed up slow steps (e.g. calc_model_gradients)


- automate creation of composite image of PMF and errors through subdivision steps

- interpolation for missing data

- GUI!

- mpi4py?

- allow multiple output variables

- animations

- hierarchical indexing to save space rather than everything written out in every row?

- alternative error models (e.g. lognormal as well as normal)

- allow arbitrary parameter space sampling (e.g. user-provided points) in Pmf? Then regions could be defined by a Voronoi tessellation rather than hyper-rectangular-prisms or whatever
